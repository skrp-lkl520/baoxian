{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0.996404\n",
      "1         0.855963\n",
      "2         0.885440\n",
      "3         0.549622\n",
      "4         0.996682\n",
      "            ...   \n",
      "684278    0.290628\n",
      "684279    0.683835\n",
      "684280    0.450370\n",
      "684281    0.598003\n",
      "684282    0.839114\n",
      "Name: label, Length: 684283, dtype: float64\n",
      "0         0.658797\n",
      "1         0.145559\n",
      "2         0.674763\n",
      "3         0.793671\n",
      "4         0.687588\n",
      "            ...   \n",
      "186920    0.992612\n",
      "186921    0.660384\n",
      "186922    0.931174\n",
      "186923    0.784321\n",
      "186924    0.522966\n",
      "Name: label, Length: 186925, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "oof_lgb=pd.read_csv(\"train.csv\")\n",
    "oof_lgb=oof_lgb['label']\n",
    "\n",
    "oof_cat=pd.read_csv(\"cat_train.csv\")\n",
    "oof_cat=oof_cat['label']\n",
    "print(oof_cat)\n",
    "predictions_lgb=pd.read_csv(\"test.csv\")\n",
    "predictions_lgb=predictions_lgb['label']\n",
    "\n",
    "predictions_cat=pd.read_csv(\"cat_test.csv\")\n",
    "predictions_cat=predictions_cat['label']\n",
    "print(predictions_cat)\n",
    "\n",
    "target=pd.read_csv(\"new_data.csv\")\n",
    "target=target[~target['y1_is_purchase'].isnull()]['y1_is_purchase']\n",
    "# print(target)\n",
    "\n",
    "test=pd.read_csv(\"new_data.csv\")\n",
    "test=test[test['y1_is_purchase'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "AUC:   0.9032368201722707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold,RepeatedKFold\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# 将lgb和cat的结果进行stacking（叠加）\n",
    "train_stack = np.vstack([oof_lgb,oof_cat]).transpose()#训练集2列特征\n",
    "test_stack = np.vstack([predictions_lgb, predictions_cat]).transpose()#测试集2列特征\n",
    "\n",
    "#贝叶斯分类器也使用交叉验证的方法，5折，重复2次，主要是避免过拟合\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=2018)\n",
    "oof_stack = np.zeros(train_stack.shape[0])#存放训练集中验证集的预测结果\n",
    "predictions = np.zeros(test_stack.shape[0])#存放测试集的预测结果\n",
    "\n",
    "#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):#target就是每一行样本的标签值\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values#划分训练集的80%\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values#划分训练集的20%做验证集\n",
    "    \n",
    "    clf_3 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=2021, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)\n",
    "\n",
    "    clf_3.fit(trn_data, trn_y)#贝叶斯训练过程，sklearn中的。\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict_proba(val_data)[:,1]    #对验证集有一个预测，用于后面计算模型的偏差\n",
    "    predictions += clf_3.predict_proba(test_stack)[:,1]  / 10 #对测试集的预测，除以10是因为5折交叉验证重复了2次\n",
    "    \n",
    "print(\"AUC:  \",roc_auc_score(target,oof_stack))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               carid     label\n",
      "684283  ZhCSxFMK2Pv4mkVwSNQeF0HwKQpm78mD4OA4t/gX79k=  0.699785\n",
      "684284  MN3k6VEj1c1yflYHmZbnChWcB4YFunAJxn2a/oNibMo=  0.080271\n",
      "684285  q0hlS2GQL/TvAvJ4QaNYOmnostsrxOd47UguA9jfsL0=  0.718266\n",
      "684286  vq73YiH8neXWAG6GLRqKNmtbcMt6VexhGjdGHpqdVTg=  0.840712\n",
      "684287  IAJ37++ziuqd5wAgRKP5maZjY0hmgqo5D5Wi1CENlsM=  0.676584\n",
      "...                                              ...       ...\n",
      "871203  3YvjqL1OhRDsNbyYEQlRUXkvdLWrmLIxBtJOWIFBmEQ=  0.949164\n",
      "871204  7eHRyIkXf7QgWEBAwakeaagN52tac6USkl5X0ltVvDw=  0.683049\n",
      "871205  2pZ0itTxXnUUgJMwOVbF6mrk2MYt+4esW/9UYP+rgoQ=  0.916347\n",
      "871206  zeVjdYP9PCFYHPeLGgq5pBGKGrAqaSVFE3kNmjMGAAU=  0.816768\n",
      "871207  rVEoH2ZFRaT/E4z9V96Y3qdUYGvelTEqcd51oHeC0Fc=  0.529543\n",
      "\n",
      "[186925 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test['label']=predictions\n",
    "res=test[['carid','label']]\n",
    "print(res)\n",
    "res.to_csv(\"stacking.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
